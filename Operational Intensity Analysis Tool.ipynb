{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operational Intensity Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import VGG16, MobileNet, Xception, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kernel_size(layer):\n",
    "    layer_type = layer.__class__.__name__\n",
    "    if 'Conv2D' in layer_type or 'Dense' in layer_type:\n",
    "        weights = layer.get_weights()\n",
    "        return weights[0].shape\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFLOPS(layer, kernel, output):\n",
    "    # For Xception\n",
    "    if \"Separable\" in layer:\n",
    "        return np.prod(output) * (np.prod(kernel[:-2]) + kernel[-2])\n",
    "    # For MobileNet\n",
    "    elif \"Depthwise\" in layer:\n",
    "        return np.prod(output) * np.prod(kernel[:-2])\n",
    "    # Regular Convolution\n",
    "    elif \"Conv2D\" in layer or \"Dense\" in layer:\n",
    "        return np.prod(output) * np.prod(kernel[:-1])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intensity(model):\n",
    "    print('Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS')\n",
    "    print('--- | --- | --- | --- | --- | --- | ---')\n",
    "    sum_kernel_mem = 0\n",
    "    sum_output_mem = 0\n",
    "    sum_flops = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        kernel_size = get_kernel_size(l)\n",
    "        kernel_mem = np.prod(kernel_size)\n",
    "        output_size = l.output_shape[1:]\n",
    "        output_mem = np.prod(output_size)\n",
    "        flops = getFLOPS(layer_type, kernel_size, output_size)\n",
    "        print(l.name, '|', layer_type, '|', \n",
    "              kernel_size, '|', \"{:,}\".format(kernel_mem), '|', \n",
    "              output_size, '|', \"{:,}\".format(output_mem), '|', \n",
    "              \"{:,}\".format(flops))\n",
    "        sum_kernel_mem += kernel_mem\n",
    "        sum_output_mem += output_mem\n",
    "        sum_flops += flops\n",
    "    print('- | - | - | - | - | - | -')\n",
    "    print('- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)')\n",
    "    print('Summary | - | - |', \n",
    "          \"{:,}\".format(sum_kernel_mem), '| - |', \n",
    "          \"{:,}\".format(sum_output_mem), '|', \n",
    "          \"{:,}\".format(sum_flops))\n",
    "    print('\\n----------------------\\n')\n",
    "    print('Model Name: %s' % model.name)\n",
    "    print('Overall FLOPS: %.f MFLOPS' % (sum_flops/1024/1024))\n",
    "    print('Overall Memory: %.f MB' % ((sum_kernel_mem + sum_output_mem)/1024/1024))\n",
    "    # Default dtype is float32 (4Byte)\n",
    "    op_intensity = sum_flops / ((sum_kernel_mem + sum_output_mem) * 4)\n",
    "    print('Operational Intensity = %.f FLOPS/Byte' % op_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_1 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "block1_conv1 | Conv2D | (3, 3, 3, 64) | 1,728 | (224, 224, 64) | 3,211,264 | 86,704,128\n",
      "block1_conv2 | Conv2D | (3, 3, 64, 64) | 36,864 | (224, 224, 64) | 3,211,264 | 1,849,688,064\n",
      "block1_pool | MaxPooling2D | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "block2_conv1 | Conv2D | (3, 3, 64, 128) | 73,728 | (112, 112, 128) | 1,605,632 | 924,844,032\n",
      "block2_conv2 | Conv2D | (3, 3, 128, 128) | 147,456 | (112, 112, 128) | 1,605,632 | 1,849,688,064\n",
      "block2_pool | MaxPooling2D | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "block3_conv1 | Conv2D | (3, 3, 128, 256) | 294,912 | (56, 56, 256) | 802,816 | 924,844,032\n",
      "block3_conv2 | Conv2D | (3, 3, 256, 256) | 589,824 | (56, 56, 256) | 802,816 | 1,849,688,064\n",
      "block3_conv3 | Conv2D | (3, 3, 256, 256) | 589,824 | (56, 56, 256) | 802,816 | 1,849,688,064\n",
      "block3_pool | MaxPooling2D | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "block4_conv1 | Conv2D | (3, 3, 256, 512) | 1,179,648 | (28, 28, 512) | 401,408 | 924,844,032\n",
      "block4_conv2 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (28, 28, 512) | 401,408 | 1,849,688,064\n",
      "block4_conv3 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (28, 28, 512) | 401,408 | 1,849,688,064\n",
      "block4_pool | MaxPooling2D | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "block5_conv1 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (14, 14, 512) | 100,352 | 462,422,016\n",
      "block5_conv2 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (14, 14, 512) | 100,352 | 462,422,016\n",
      "block5_conv3 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (14, 14, 512) | 100,352 | 462,422,016\n",
      "block5_pool | MaxPooling2D | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "flatten | Flatten | 0 | 0 | (25088,) | 25,088 | 0\n",
      "fc1 | Dense | (25088, 4096) | 102,760,448 | (4096,) | 4,096 | 102,760,448\n",
      "fc2 | Dense | (4096, 4096) | 16,777,216 | (4096,) | 4,096 | 16,777,216\n",
      "predictions | Dense | (4096, 1000) | 4,096,000 | (1000,) | 1,000 | 4,096,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 138,344,128 | - | 15,262,696 | 15,470,264,320\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: vgg16\n",
      "Overall FLOPS: 14754 MFLOPS\n",
      "Overall Memory: 146 MB\n",
      "Operational Intensity = 25 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(VGG16())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_2 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "conv1 | Conv2D | (3, 3, 3, 32) | 864 | (112, 112, 32) | 401,408 | 10,838,016\n",
      "conv1_bn | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv1_relu | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv_dw_1 | DepthwiseConv2D | (3, 3, 32, 1) | 288 | (112, 112, 32) | 401,408 | 3,612,672\n",
      "conv_dw_1_bn | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv_dw_1_relu | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv_pw_1 | Conv2D | (1, 1, 32, 64) | 2,048 | (112, 112, 64) | 802,816 | 25,690,112\n",
      "conv_pw_1_bn | BatchNormalization | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "conv_pw_1_relu | Activation | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "conv_dw_2 | DepthwiseConv2D | (3, 3, 64, 1) | 576 | (56, 56, 64) | 200,704 | 1,806,336\n",
      "conv_dw_2_bn | BatchNormalization | 0 | 0 | (56, 56, 64) | 200,704 | 0\n",
      "conv_dw_2_relu | Activation | 0 | 0 | (56, 56, 64) | 200,704 | 0\n",
      "conv_pw_2 | Conv2D | (1, 1, 64, 128) | 8,192 | (56, 56, 128) | 401,408 | 25,690,112\n",
      "conv_pw_2_bn | BatchNormalization | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_pw_2_relu | Activation | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_dw_3 | DepthwiseConv2D | (3, 3, 128, 1) | 1,152 | (56, 56, 128) | 401,408 | 3,612,672\n",
      "conv_dw_3_bn | BatchNormalization | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_dw_3_relu | Activation | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_pw_3 | Conv2D | (1, 1, 128, 128) | 16,384 | (56, 56, 128) | 401,408 | 51,380,224\n",
      "conv_pw_3_bn | BatchNormalization | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_pw_3_relu | Activation | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_dw_4 | DepthwiseConv2D | (3, 3, 128, 1) | 1,152 | (28, 28, 128) | 100,352 | 903,168\n",
      "conv_dw_4_bn | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "conv_dw_4_relu | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "conv_pw_4 | Conv2D | (1, 1, 128, 256) | 32,768 | (28, 28, 256) | 200,704 | 25,690,112\n",
      "conv_pw_4_bn | BatchNormalization | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_pw_4_relu | Activation | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_dw_5 | DepthwiseConv2D | (3, 3, 256, 1) | 2,304 | (28, 28, 256) | 200,704 | 1,806,336\n",
      "conv_dw_5_bn | BatchNormalization | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_dw_5_relu | Activation | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_pw_5 | Conv2D | (1, 1, 256, 256) | 65,536 | (28, 28, 256) | 200,704 | 51,380,224\n",
      "conv_pw_5_bn | BatchNormalization | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_pw_5_relu | Activation | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_dw_6 | DepthwiseConv2D | (3, 3, 256, 1) | 2,304 | (14, 14, 256) | 50,176 | 451,584\n",
      "conv_dw_6_bn | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "conv_dw_6_relu | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "conv_pw_6 | Conv2D | (1, 1, 256, 512) | 131,072 | (14, 14, 512) | 100,352 | 25,690,112\n",
      "conv_pw_6_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_6_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_7 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_7_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_7_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_7 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_7_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_7_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_8 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_8_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_8_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_8 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_8_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_8_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_9 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_9_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_9_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_9 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_9_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_9_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_10 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_10_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_10_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_10 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_10_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_10_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_11 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_11_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_11_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_11 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_11_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_11_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_12 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (7, 7, 512) | 25,088 | 225,792\n",
      "conv_dw_12_bn | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "conv_dw_12_relu | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "conv_pw_12 | Conv2D | (1, 1, 512, 1024) | 524,288 | (7, 7, 1024) | 50,176 | 25,690,112\n",
      "conv_pw_12_bn | BatchNormalization | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_pw_12_relu | Activation | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_dw_13 | DepthwiseConv2D | (3, 3, 1024, 1) | 9,216 | (7, 7, 1024) | 50,176 | 451,584\n",
      "conv_dw_13_bn | BatchNormalization | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_dw_13_relu | Activation | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_pw_13 | Conv2D | (1, 1, 1024, 1024) | 1,048,576 | (7, 7, 1024) | 50,176 | 51,380,224\n",
      "conv_pw_13_bn | BatchNormalization | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_pw_13_relu | Activation | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "global_average_pooling2d_1 | GlobalAveragePooling2D | 0 | 0 | (1024,) | 1,024 | 0\n",
      "reshape_1 | Reshape | 0 | 0 | (1, 1, 1024) | 1,024 | 0\n",
      "dropout | Dropout | 0 | 0 | (1, 1, 1024) | 1,024 | 0\n",
      "conv_preds | Conv2D | (1, 1, 1024, 1000) | 1,024,000 | (1, 1, 1000) | 1,000 | 1,024,000\n",
      "act_softmax | Activation | 0 | 0 | (1, 1, 1000) | 1,000 | 0\n",
      "reshape_2 | Reshape | 0 | 0 | (1000,) | 1,000 | 0\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 4,209,088 | - | 15,284,664 | 568,740,352\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: mobilenet_1.00_224\n",
      "Overall FLOPS: 542 MFLOPS\n",
      "Overall Memory: 19 MB\n",
      "Operational Intensity = 7 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(MobileNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_4 | InputLayer | 0 | 0 | (299, 299, 3) | 268,203 | 0\n",
      "block1_conv1 | Conv2D | (3, 3, 3, 32) | 864 | (149, 149, 32) | 710,432 | 19,181,664\n",
      "block1_conv1_bn | BatchNormalization | 0 | 0 | (149, 149, 32) | 710,432 | 0\n",
      "block1_conv1_act | Activation | 0 | 0 | (149, 149, 32) | 710,432 | 0\n",
      "block1_conv2 | Conv2D | (3, 3, 32, 64) | 18,432 | (147, 147, 64) | 1,382,976 | 398,297,088\n",
      "block1_conv2_bn | BatchNormalization | 0 | 0 | (147, 147, 64) | 1,382,976 | 0\n",
      "block1_conv2_act | Activation | 0 | 0 | (147, 147, 64) | 1,382,976 | 0\n",
      "block2_sepconv1 | SeparableConv2D | (3, 3, 64, 1) | 576 | (147, 147, 128) | 2,765,952 | 201,914,496\n",
      "block2_sepconv1_bn | BatchNormalization | 0 | 0 | (147, 147, 128) | 2,765,952 | 0\n",
      "block2_sepconv2_act | Activation | 0 | 0 | (147, 147, 128) | 2,765,952 | 0\n",
      "block2_sepconv2 | SeparableConv2D | (3, 3, 128, 1) | 1,152 | (147, 147, 128) | 2,765,952 | 378,935,424\n",
      "block2_sepconv2_bn | BatchNormalization | 0 | 0 | (147, 147, 128) | 2,765,952 | 0\n",
      "conv2d_5 | Conv2D | (1, 1, 64, 128) | 8,192 | (74, 74, 128) | 700,928 | 44,859,392\n",
      "block2_pool | MaxPooling2D | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "batch_normalization_5 | BatchNormalization | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "add_13 | Add | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "block3_sepconv1_act | Activation | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "block3_sepconv1 | SeparableConv2D | (3, 3, 128, 1) | 1,152 | (74, 74, 256) | 1,401,856 | 192,054,272\n",
      "block3_sepconv1_bn | BatchNormalization | 0 | 0 | (74, 74, 256) | 1,401,856 | 0\n",
      "block3_sepconv2_act | Activation | 0 | 0 | (74, 74, 256) | 1,401,856 | 0\n",
      "block3_sepconv2 | SeparableConv2D | (3, 3, 256, 1) | 2,304 | (74, 74, 256) | 1,401,856 | 371,491,840\n",
      "block3_sepconv2_bn | BatchNormalization | 0 | 0 | (74, 74, 256) | 1,401,856 | 0\n",
      "conv2d_6 | Conv2D | (1, 1, 128, 256) | 32,768 | (37, 37, 256) | 350,464 | 44,859,392\n",
      "block3_pool | MaxPooling2D | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "batch_normalization_6 | BatchNormalization | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "add_14 | Add | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "block4_sepconv1_act | Activation | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "block4_sepconv1 | SeparableConv2D | (3, 3, 256, 1) | 2,304 | (37, 37, 728) | 996,632 | 264,107,480\n",
      "block4_sepconv1_bn | BatchNormalization | 0 | 0 | (37, 37, 728) | 996,632 | 0\n",
      "block4_sepconv2_act | Activation | 0 | 0 | (37, 37, 728) | 996,632 | 0\n",
      "block4_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (37, 37, 728) | 996,632 | 734,517,784\n",
      "block4_sepconv2_bn | BatchNormalization | 0 | 0 | (37, 37, 728) | 996,632 | 0\n",
      "conv2d_7 | Conv2D | (1, 1, 256, 728) | 186,368 | (19, 19, 728) | 262,808 | 67,278,848\n",
      "block4_pool | MaxPooling2D | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "batch_normalization_7 | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_15 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block5_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block5_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block5_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_16 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block6_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block6_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block6_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_17 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block7_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block7_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block7_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_18 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block8_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block8_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block8_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_19 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block9_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block9_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block9_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_20 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block10_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block10_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block10_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_21 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block11_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block11_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block11_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_22 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block12_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block12_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block12_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_23 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block13_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 1024) | 369,664 | 272,442,368\n",
      "block13_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 1024) | 369,664 | 0\n",
      "conv2d_8 | Conv2D | (1, 1, 728, 1024) | 745,472 | (10, 10, 1024) | 102,400 | 74,547,200\n",
      "block13_pool | MaxPooling2D | 0 | 0 | (10, 10, 1024) | 102,400 | 0\n",
      "batch_normalization_8 | BatchNormalization | 0 | 0 | (10, 10, 1024) | 102,400 | 0\n",
      "add_24 | Add | 0 | 0 | (10, 10, 1024) | 102,400 | 0\n",
      "block14_sepconv1 | SeparableConv2D | (3, 3, 1024, 1) | 9,216 | (10, 10, 1536) | 153,600 | 158,668,800\n",
      "block14_sepconv1_bn | BatchNormalization | 0 | 0 | (10, 10, 1536) | 153,600 | 0\n",
      "block14_sepconv1_act | Activation | 0 | 0 | (10, 10, 1536) | 153,600 | 0\n",
      "block14_sepconv2 | SeparableConv2D | (3, 3, 1536, 1) | 13,824 | (10, 10, 2048) | 204,800 | 316,416,000\n",
      "block14_sepconv2_bn | BatchNormalization | 0 | 0 | (10, 10, 2048) | 204,800 | 0\n",
      "block14_sepconv2_act | Activation | 0 | 0 | (10, 10, 2048) | 204,800 | 0\n",
      "avg_pool | GlobalAveragePooling2D | 0 | 0 | (2048,) | 2,048 | 0\n",
      "predictions | Dense | (2048, 1000) | 2,048,000 | (1000,) | 1,000 | 2,048,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 3,247,528 | - | 62,981,867 | 8,383,857,448\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: xception\n",
      "Overall FLOPS: 7995 MFLOPS\n",
      "Overall Memory: 63 MB\n",
      "Operational Intensity = 32 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(Xception(input_shape=(299, 299, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_5 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "conv1 | Conv2D | (7, 7, 3, 64) | 9,408 | (112, 112, 64) | 802,816 | 118,013,952\n",
      "bn_conv1 | BatchNormalization | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "activation_1 | Activation | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "max_pooling2d_1 | MaxPooling2D | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2a_branch2a | Conv2D | (1, 1, 64, 64) | 4,096 | (55, 55, 64) | 193,600 | 12,390,400\n",
      "bn2a_branch2a | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_2 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2a_branch2b | Conv2D | (3, 3, 64, 64) | 36,864 | (55, 55, 64) | 193,600 | 111,513,600\n",
      "bn2a_branch2b | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_3 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2a_branch2c | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "res2a_branch1 | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "bn2a_branch2c | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "bn2a_branch1 | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "add_25 | Add | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "activation_4 | Activation | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "res2b_branch2a | Conv2D | (1, 1, 256, 64) | 16,384 | (55, 55, 64) | 193,600 | 49,561,600\n",
      "bn2b_branch2a | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_5 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2b_branch2b | Conv2D | (3, 3, 64, 64) | 36,864 | (55, 55, 64) | 193,600 | 111,513,600\n",
      "bn2b_branch2b | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_6 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2b_branch2c | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "bn2b_branch2c | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "add_26 | Add | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "activation_7 | Activation | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "res2c_branch2a | Conv2D | (1, 1, 256, 64) | 16,384 | (55, 55, 64) | 193,600 | 49,561,600\n",
      "bn2c_branch2a | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_8 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2c_branch2b | Conv2D | (3, 3, 64, 64) | 36,864 | (55, 55, 64) | 193,600 | 111,513,600\n",
      "bn2c_branch2b | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_9 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2c_branch2c | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "bn2c_branch2c | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "add_27 | Add | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "activation_10 | Activation | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "res3a_branch2a | Conv2D | (1, 1, 256, 128) | 32,768 | (28, 28, 128) | 100,352 | 25,690,112\n",
      "bn3a_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_11 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3a_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3a_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_12 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3a_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "res3a_branch1 | Conv2D | (1, 1, 256, 512) | 131,072 | (28, 28, 512) | 401,408 | 102,760,448\n",
      "bn3a_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "bn3a_branch1 | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_28 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_13 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res3b_branch2a | Conv2D | (1, 1, 512, 128) | 65,536 | (28, 28, 128) | 100,352 | 51,380,224\n",
      "bn3b_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_14 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3b_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3b_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_15 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3b_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "bn3b_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_29 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_16 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res3c_branch2a | Conv2D | (1, 1, 512, 128) | 65,536 | (28, 28, 128) | 100,352 | 51,380,224\n",
      "bn3c_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_17 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3c_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3c_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_18 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3c_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "bn3c_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_30 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_19 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res3d_branch2a | Conv2D | (1, 1, 512, 128) | 65,536 | (28, 28, 128) | 100,352 | 51,380,224\n",
      "bn3d_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_20 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3d_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3d_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_21 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3d_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "bn3d_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_31 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_22 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res4a_branch2a | Conv2D | (1, 1, 512, 256) | 131,072 | (14, 14, 256) | 50,176 | 25,690,112\n",
      "bn4a_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_23 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4a_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4a_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_24 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4a_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "res4a_branch1 | Conv2D | (1, 1, 512, 1024) | 524,288 | (14, 14, 1024) | 200,704 | 102,760,448\n",
      "bn4a_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "bn4a_branch1 | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_32 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_25 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4b_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4b_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_26 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4b_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4b_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_27 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4b_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4b_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_33 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_28 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4c_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4c_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_29 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4c_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4c_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_30 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4c_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4c_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_34 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_31 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4d_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4d_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_32 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4d_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4d_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_33 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4d_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4d_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_35 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_34 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4e_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4e_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_35 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4e_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4e_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_36 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4e_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4e_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_36 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_37 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4f_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4f_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_38 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4f_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4f_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_39 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4f_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4f_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_37 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_40 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res5a_branch2a | Conv2D | (1, 1, 1024, 512) | 524,288 | (7, 7, 512) | 25,088 | 25,690,112\n",
      "bn5a_branch2a | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_41 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5a_branch2b | Conv2D | (3, 3, 512, 512) | 2,359,296 | (7, 7, 512) | 25,088 | 115,605,504\n",
      "bn5a_branch2b | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_42 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5a_branch2c | Conv2D | (1, 1, 512, 2048) | 1,048,576 | (7, 7, 2048) | 100,352 | 51,380,224\n",
      "res5a_branch1 | Conv2D | (1, 1, 1024, 2048) | 2,097,152 | (7, 7, 2048) | 100,352 | 102,760,448\n",
      "bn5a_branch2c | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "bn5a_branch1 | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "add_38 | Add | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "activation_43 | Activation | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "res5b_branch2a | Conv2D | (1, 1, 2048, 512) | 1,048,576 | (7, 7, 512) | 25,088 | 51,380,224\n",
      "bn5b_branch2a | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_44 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5b_branch2b | Conv2D | (3, 3, 512, 512) | 2,359,296 | (7, 7, 512) | 25,088 | 115,605,504\n",
      "bn5b_branch2b | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_45 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5b_branch2c | Conv2D | (1, 1, 512, 2048) | 1,048,576 | (7, 7, 2048) | 100,352 | 51,380,224\n",
      "bn5b_branch2c | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "add_39 | Add | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "activation_46 | Activation | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "res5c_branch2a | Conv2D | (1, 1, 2048, 512) | 1,048,576 | (7, 7, 512) | 25,088 | 51,380,224\n",
      "bn5c_branch2a | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_47 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5c_branch2b | Conv2D | (3, 3, 512, 512) | 2,359,296 | (7, 7, 512) | 25,088 | 115,605,504\n",
      "bn5c_branch2b | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_48 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5c_branch2c | Conv2D | (1, 1, 512, 2048) | 1,048,576 | (7, 7, 2048) | 100,352 | 51,380,224\n",
      "bn5c_branch2c | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "add_40 | Add | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "activation_49 | Activation | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "avg_pool | AveragePooling2D | 0 | 0 | (1, 1, 2048) | 2,048 | 0\n",
      "flatten_1 | Flatten | 0 | 0 | (2048,) | 2,048 | 0\n",
      "fc1000 | Dense | (2048, 1000) | 2,048,000 | (1000,) | 1,000 | 2,048,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 25,502,912 | - | 35,599,016 | 3,834,331,136\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: resnet50\n",
      "Overall FLOPS: 3657 MFLOPS\n",
      "Overall Memory: 58 MB\n",
      "Operational Intensity = 16 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(ResNet50())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
